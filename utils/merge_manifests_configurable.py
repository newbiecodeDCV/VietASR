#!/usr/bin/env python3
"""
Script g·ªôp manifests t·ª´ nhi·ªÅu dataset v·ªõi ƒë∆∞·ªùng d·∫´n train/test ri√™ng bi·ªát.
T∆Ø∆†NG TH√çCH V·ªöI LHOTSE 1.31.1.dev (s·ª≠a l·ªói lazy iterator sau shuffle)
"""

from pathlib import Path
from typing import List, Tuple
from lhotse import CutSet, load_manifest_lazy
from lhotse.utils import fix_random_seed


TRAIN_DIR = Path("manifests/")
TEST_DIR = Path("manifests/")
TRAIN_DATASETS: List[str] = ["regions_63","regions.bac_trung_bo","regions.bac_trung_bo_112024","regions.dong_nam_bo","tongdai","tongdai_02112022","tongdai_25112024","regions.tongdai"]
TEST_DATASETS: List[str] = []
TRAIN_RATIO = 0.95
OUTPUT_DIR = Path("data4/manifests")
# ====== END CONFIG ======


def load_dataset(data_dir: Path, name: str) -> CutSet:
    """Load m·ªôt dataset t·ª´ recordings v√† supervisions."""
    rec_file = data_dir / name / f"recordings_{name}.jsonl.gz"
    sup_file = data_dir / name / f"supervisions_{name}.jsonl.gz"
    
    if not rec_file.exists() or not sup_file.exists():
        raise FileNotFoundError(f"Dataset {name} thi·∫øu file: {rec_file} ho·∫∑c {sup_file}")
    
    print(f"  üìÇ Loading {data_dir.name}/{name}...")
    return CutSet.from_manifests(
        recordings=load_manifest_lazy(rec_file),
        supervisions=load_manifest_lazy(sup_file)
    )


def merge_datasets(data_dir: Path, names: List[str]) -> CutSet:
    """G·ªôp nhi·ªÅu dataset t·ª´ c√πng m·ªôt folder th√†nh m·ªôt CutSet."""
    if not names:
        print("  ‚ö†Ô∏è  Kh√¥ng c√≥ dataset n√†o ƒë·ªÉ g·ªôp!")
        return CutSet([])
    
    cuts_list = [load_dataset(data_dir, name) for name in names]
    print(f"  üîÄ G·ªôp {len(names)} datasets t·ª´ {data_dir.name}...")
    
    # T∆Ø∆†NG TH√çCH M·ªåI PHI√äN B·∫¢N: D√πng to√°n t·ª≠ + qua sum()
    return sum(cuts_list, CutSet([]))


def split_train_dev(cuts: CutSet, train_ratio: float) -> Tuple[CutSet, CutSet]:
    """Chia CutSet th√†nh train v√† dev theo t·ª∑ l·ªá.
    
    FIX CHO LHOTSE 1.31.1.dev:
    - Sau shuffle() tr·ªü th√†nh lazy iterator
    - Ph·∫£i d√πng subset(first=N) thay v√¨ slicing
    - Ho·∫∑c materialize to√†n b·ªô v·ªõi to_eager()
    """
    if len(cuts) == 0:
        return CutSet([]), CutSet([])
    
    # Set seed to√†n c·ª•c tr∆∞·ªõc khi shuffle
    fix_random_seed(42)
    cuts = cuts.shuffle()  # Tr·∫£ v·ªÅ lazy iterator
    
    # SOLUTION 1: D√πng subset() v·ªõi first/last
    total = len(cuts)
    train_size = int(train_ratio * total)
    
    # L·∫•y train_size ph·∫ßn t·ª≠ ƒë·∫ßu
    train_cuts = cuts.subset(first=train_size)
    
    # L·∫•y ph·∫ßn c√≤n l·∫°i: skip train_size ph·∫ßn t·ª≠ ƒë·∫ßu
    dev_cuts = cuts.subset(last=total - train_size)
    
    return train_cuts, dev_cuts


def main():
    print("=" * 70)
    print("B·∫Øt ƒë·∫ßu g·ªôp manifests...")
    print("Lhotse version: 1.31.1.dev (fix lazy iterator)")
    print("=" * 70)
    
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
    
    print(f"üìç Train folder: {TRAIN_DIR}")
    print(f"üìç Test folder:  {TEST_DIR}")
    
    # ===== X·ª¨ L√ù TRAIN/DEV =====
    print("\nüéØ X·ª≠ l√Ω train/dev datasets:")
    if TRAIN_DATASETS:
        print(f"  Danh s√°ch: {', '.join(TRAIN_DATASETS)}")
        
        combined_cuts = merge_datasets(TRAIN_DIR, TRAIN_DATASETS)
        print(f"  T·ªïng s·ªë utterances: {len(combined_cuts)}")
        
        train_cuts, dev_cuts = split_train_dev(combined_cuts, TRAIN_RATIO)
        print(f"  ‚Üí Train: {len(train_cuts)} utterances ({TRAIN_RATIO:.0%})")
        print(f"  ‚Üí Dev: {len(dev_cuts)} utterances ({1-TRAIN_RATIO:.0%})")
        
        train_cuts.to_file(OUTPUT_DIR / "vietASR_cuts_train.jsonl.gz")
        dev_cuts.to_file(OUTPUT_DIR / "vietASR_cuts_dev.jsonl.gz")
        print("  ‚úÖ ƒê√£ l∆∞u train/dev cuts")
    else:
        print("  ‚ö†Ô∏è  Kh√¥ng c√≥ dataset n√†o cho train/dev")
    
    # ===== X·ª¨ L√ù TEST =====
    print("\nüß™ X·ª≠ l√Ω test datasets:")
    if TEST_DATASETS:
        print(f"  Danh s√°ch: {', '.join(TEST_DATASETS)}")
        
        test_cuts = merge_datasets(TEST_DIR, TEST_DATASETS)
        print(f"  T·ªïng s·ªë utterances: {len(test_cuts)}")
        
        test_cuts.to_file(OUTPUT_DIR / "vietASR_cuts_test.jsonl.gz")
        print("  ‚úÖ ƒê√£ l∆∞u test cuts")
    else:
        print("  ‚ö†Ô∏è  Kh√¥ng c√≥ dataset n√†o cho test")
    
    print("\n" + "=" * 70)
    print("‚úÖ HO√ÄN TH√ÄNH!")
    print(f"üìÅ Output: {OUTPUT_DIR}")
    print("=" * 70)


if __name__ == "__main__":
    main()