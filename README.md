# VietASR - Vietnamese Speech Recognition

> ASR system cho tiáº¿ng Viá»‡t sá»­ dá»¥ng Zipformer + BPE, há»— trá»£ SSL pretraining vÃ  LM decoding.

## ğŸ“ Cáº¥u trÃºc Project

```
VietASR/
â”œâ”€â”€ ASR/                          # ASR Training Framework
â”‚   â”œâ”€â”€ zipformer/                # Zipformer model
â”‚   â”œâ”€â”€ local/                    # Data preparation
â”‚   â””â”€â”€ scripts/                  # Training scripts
â”‚
â”œâ”€â”€ SSL/                          # Self-Supervised Learning
â”‚   â”œâ”€â”€ zipformer_fbank/          # Main SSL + Finetune code
â”‚   â”‚   â”œâ”€â”€ finetune.py          # Finetune script
â”‚   â”‚   â”œâ”€â”€ decode.py            # Decode script
â”‚   â”‚   â””â”€â”€ beam_search.py       # Decoding methods
â”‚   â”œâ”€â”€ shared/                   # Shared utilities (make_kn_lm.py)
â”‚   â””â”€â”€ scripts/                  # Training scripts
â”‚
â”œâ”€â”€ scripts/                      # Utility Scripts
â”‚   â”œâ”€â”€ data/                     # Data preparation
â”‚   â”‚   â”œâ”€â”€ normalize_*.py       # Text normalization
â”‚   â”‚   â””â”€â”€ combine_manifests.py # Manifest processing
â”‚   â”œâ”€â”€ decode/                   # Decode scripts
â”‚   â”‚   â”œâ”€â”€ decode.sh            # Baseline decode
â”‚   â”‚   â””â”€â”€ decode_with_lm.sh    # Decode vá»›i LM
â”‚   â”œâ”€â”€ lm/                       # Language Model
â”‚   â”‚   â”œâ”€â”€ 01_tokenize_corpus.sh
â”‚   â”‚   â”œâ”€â”€ 02_train_lm.sh
â”‚   â”‚   â””â”€â”€ 03_decode_with_lm.sh
â”‚   â””â”€â”€ *.py                      # Other utilities
â”‚
â”œâ”€â”€ utils/                        # Core Utilities
â”‚   â”œâ”€â”€ tokenize_corpus_for_lm.py # LM tokenization
â”‚   â”œâ”€â”€ extract_text_for_lm.py   # Extract text from manifest
â”‚   â””â”€â”€ compile_lg.py            # Compile LG graph
â”‚
â”œâ”€â”€ data4/                        # Data & Experiments
â”‚   â”œâ”€â”€ exp*/                     # Experiment checkpoints
â”‚   â”œâ”€â”€ fbank/                    # Fbank features
â”‚   â”œâ”€â”€ lm/                       # Trained LMs
â”‚   â””â”€â”€ lm_corpus/                # LM training data
â”‚
â”œâ”€â”€ viet_iter3_pseudo_label/      # Pretrained checkpoint
â”‚   â””â”€â”€ data/Vietnam_bpe_2000_new/
â”‚       â”œâ”€â”€ bpe.model            # BPE model
â”‚       â””â”€â”€ tokens.txt           # Token vocabulary
â”‚
â””â”€â”€ docker/                       # Docker configuration
```

## ğŸš€ Quick Start

### 1. Finetune Model

```bash
# Trong Docker container
cd /vietasr

python SSL/zipformer_fbank/finetune.py \
    --world-size 1 \
    --num-epochs 10 \
    --exp-dir data4/exp_finetune \
    --bpe-model viet_iter3_pseudo_label/data/Vietnam_bpe_2000_new/bpe.model \
    --manifest-dir data4/fbank \
    --base-lr 0.0003 \
    --use-layer-norm 0
```

### 2. Decode

```bash
# Baseline (khÃ´ng LM)
python SSL/zipformer_fbank/decode.py \
    --epoch 10 --avg 5 \
    --exp-dir data4/exp \
    --bpe-model viet_iter3_pseudo_label/data/Vietnam_bpe_2000_new/bpe.model \
    --manifest-dir data4/fbank \
    --decoding-method modified_beam_search \
    --use-layer-norm 0 \
    --cuts-name dev
```

### 3. Train & Decode vá»›i LM

```bash
# Step 1: Tokenize corpus
bash scripts/lm/01_tokenize_corpus.sh data4/lm_corpus/all.txt data4/lm_corpus/all_bpe_ids.txt

# Step 2: Train LM
bash scripts/lm/02_train_lm.sh data4/lm_corpus/all_bpe_ids.txt data4/lm/lm_4gram_bpe.arpa 4

# Step 3: Decode vá»›i LM
bash scripts/lm/03_decode_with_lm.sh --epoch 10 --avg 5 \
    --lm-path data4/lm/lm_4gram_bpe.arpa --lm-scale 0.3
```

## ğŸ“‹ Scripts Reference

| Script | MÃ´ táº£ |
|--------|-------|
| `scripts/lm/01_tokenize_corpus.sh` | Tokenize text â†’ BPE IDs |
| `scripts/lm/02_train_lm.sh` | Train n-gram LM |
| `scripts/lm/03_decode_with_lm.sh` | Decode vá»›i LM shallow fusion |
| `scripts/lm/decode_baseline.sh` | Decode baseline |
| `scripts/lm/compare_wer.sh` | So sÃ¡nh WER |
| `scripts/data/normalize_*.py` | Normalize text |
| `scripts/filter_bad_labels.py` | Filter WER-based |

## âš™ï¸ Key Parameters

### Decode parameters (cho `viet_iter3_pseudo_label` checkpoint)

```bash
--use-layer-norm 0      # Báº®T BUá»˜C
--final-downsample 1    # CÃ³ thá»ƒ bá»
--beam-size 10          # Beam size
```

### LM parameters

```bash
--arpa-lm-scale 0.3     # LM weight (tune: 0.1-0.7)
--decoding-method modified_beam_search_lm_shallow_fusion
```

## ğŸ“Š Experiments

| Exp Dir | MÃ´ táº£ |
|---------|-------|
| `data4/exp` | Main experiments |
| `data4/exp_finetune` | Finetune experiments |
| `data4/exp_tongdai` | Tá»•ng Ä‘Ã i experiments |

## ğŸ³ Docker

```bash
# Attach vÃ o container
docker exec -it hiennt_vietasr_gpu_20251121T2348 bash

# Working directory
cd /vietasr
```
